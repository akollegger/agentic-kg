{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Np0plMPXRvoq"
      },
      "source": [
        "# File Suggestions\n",
        "\n",
        "The next phase of knowledge graph is to suggest files to use for import, based on the established user goal.\n",
        "\n",
        "## Agent\n",
        "\n",
        "- An agent that suggests files to use for import, based on the established user goal.\n",
        "- Input: `approved_user_goal`, a dictionary pairing a kind of graph with a description of the purpose of the graph.\n",
        "- Output: `approved_file_suggestions`, a list of files that have been approved for import.\n",
        "- Tools: `get_approved_user_goal`, `list_import_files`, `sample_file`, `set_suggested_files`, `approve_suggested_files`\n",
        "\n",
        "## Workflow\n",
        "\n",
        "1. The context is initialized with an `approved_user_goal` (which will get retrieved using a tool)\n",
        "2. The agent analyzes the available files, evaluating them for relevance to the established user goal.\n",
        "3. The agent suggests a list of files to import.\n",
        "4. The user approves the file suggestions.\n",
        "5. The file suggestions are saved in the context state as `approved_file_suggestions`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "The usual import of needed libraries, loading of environment variables, and connection to Neo4j."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbwxKypOSBkN"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "from itertools import islice\n",
        "\n",
        "from google.adk.agents import Agent\n",
        "from google.adk.models.lite_llm import LiteLlm # For OpenAI support\n",
        "from google.adk.sessions import InMemorySessionService\n",
        "from google.adk.runners import Runner\n",
        "from google.adk.tools import ToolContext\n",
        "from google.genai import types # For creating message Content/Parts\n",
        "\n",
        "# For type hints\n",
        "from typing import Dict, Any, List\n",
        "\n",
        "# Convenience libraries for working with Neo4j inside of Google ADK\n",
        "from neo4j_for_adk import graphdb, tool_success, tool_error\n",
        "\n",
        "import warnings\n",
        "# Ignore all warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(level=logging.CRITICAL)\n",
        "\n",
        "print(\"Libraries imported.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MI_qvZJrSJuR"
      },
      "outputs": [],
      "source": [
        "# --- Define Model Constants for easier use ---\n",
        "MODEL_GPT_4O = \"openai/gpt-4o\"\n",
        "\n",
        "llm = LiteLlm(model=MODEL_GPT_4O)\n",
        "\n",
        "# Test LLM with a direct call\n",
        "print(llm.llm_client.completion(model=llm.model, messages=[{\"role\": \"user\", \"content\": \"Are you ready?\"}], tools=[]))\n",
        "\n",
        "print(\"\\nEnvironment configured.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check connection to Neo4j by sending a query\n",
        "\n",
        "neo4j_is_ready = graphdb.send_query(\"RETURN 'Neo4j is Ready!' as message\")\n",
        "\n",
        "print(neo4j_is_ready)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the File Suggestion Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Agent Instructions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# First, define the instruction to describe what the agent should do\n",
        "file_suggestion_agent_instruction = \"\"\"\n",
        "        You are a constructive critic AI reviewing a list of files. Your goal is to suggest relevant files.\n",
        "\n",
        "        **Task:**\n",
        "        Review the file list for relevance to the kind of graph and description specified in: '{{approved_user_goal}}'. \n",
        "\n",
        "        For any file that you're not sure about, use the 'sample_file' tool to get \n",
        "        a better understanding of the file contents. \n",
        "        You do not need to sample every file. Assume markdown files in the same directory have similar features.\n",
        "        Sample only a few markdown files, and if they are relevant suggest every markdown file in the directory.\n",
        "\n",
        "        Think carefully, repeating these steps until finished:\n",
        "        1. list available files\n",
        "        2. evaluate the relevance of each file, then set the list of suggested files using the 'set_suggested_files' tool\n",
        "        3. ask the user to approve the set of suggested files\n",
        "        4. If the user has feedback, go back to step 1 with that feedback in mind\n",
        "        5. If approved, use the 'approve_suggested_files' tool to record the approval\n",
        "        \"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tool Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import tools defined in previous notebook\n",
        "from tools import get_approved_user_goal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#  Tool: List Import Files\n",
        "\n",
        "ALL_AVAILABLE_FILES = \"all_available_files\"\n",
        "\n",
        "def list_import_files(tool_context:ToolContext) -> dict:\n",
        "    f\"\"\"Lists files available in the configured Neo4j import directory\n",
        "    that are ready for import by Neo4j.\n",
        "\n",
        "    Saves the list to {ALL_AVAILABLE_FILES} in state.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing metadata about the content.\n",
        "                Includes a 'status' key ('success' or 'error').\n",
        "                If 'success', includes a {ALL_AVAILABLE_FILES} key with list of file names.\n",
        "                If 'error', includes an 'error_message' key.\n",
        "                The 'error_message' may have instructions about how to handle the error.\n",
        "    \"\"\"\n",
        "    import_dir_result = graphdb.get_import_directory() # use the helper available in Neo4jForADK\n",
        "    if import_dir_result[\"status\"] == \"error\": return import_dir_result\n",
        "    import_dir = Path(import_dir_result[\"neo4j_import_dir\"])\n",
        "\n",
        "    file_names = [str(x.relative_to(import_dir)) \n",
        "                 for x in import_dir.rglob(\"*\") \n",
        "                 if x.is_file()]\n",
        "\n",
        "    tool_context.state[ALL_AVAILABLE_FILES] = file_names\n",
        "\n",
        "    return tool_success(ALL_AVAILABLE_FILES, file_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tool: Sample File\n",
        "def sample_file(file_path: str, tool_context: ToolContext) -> dict:\n",
        "    \"\"\"Samples a file by reading its content as text.\n",
        "    \n",
        "    Treats any file as text and reads up to a maximum of 100 lines.\n",
        "    \n",
        "    Args:\n",
        "      file_path: file to sample, relative to the import directory\n",
        "      tool_context: ToolContext object\n",
        "      \n",
        "    Returns:\n",
        "        dict: A dictionary containing metadata about the content,\n",
        "              along with a sampling of the file.\n",
        "              Includes a 'status' key ('success' or 'error').\n",
        "              If 'success', includes a 'content' key with textual file content.\n",
        "              If 'error', includes an 'error_message' key.\n",
        "    \"\"\"\n",
        "    import_dir_result = graphdb.get_import_directory() # use the helper available in Neo4jForADK\n",
        "    if import_dir_result[\"status\"] == \"error\": return import_dir_result\n",
        "    import_dir = Path(import_dir_result[\"neo4j_import_dir\"])\n",
        "\n",
        "    full_path_to_file = import_dir / file_path\n",
        "    \n",
        "    if not full_path_to_file.exists():\n",
        "        return tool_error(f\"File does not exist in import directory: {file_path}\")\n",
        "    \n",
        "    try:\n",
        "        # Treat all files as text\n",
        "        with open(full_path_to_file, 'r', encoding='utf-8') as file:\n",
        "            # Read up to 100 lines\n",
        "            lines = list(islice(file, 100))\n",
        "            content = ''.join(lines)\n",
        "            return tool_success(\"content\", content)\n",
        "    \n",
        "    except Exception as e:\n",
        "        return tool_error(f\"Error reading or processing file {file_path}: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "SUGGESTED_FILES = \"suggested_files\"\n",
        "\n",
        "def set_suggested_files(suggest_files:List[str], tool_context:ToolContext) -> Dict[str, Any]:\n",
        "    \"\"\"Set the files to be used for data import.\n",
        "    \"\"\"\n",
        "    tool_context.state[SUGGESTED_FILES] = suggest_files\n",
        "    return tool_success(SUGGESTED_FILES, suggest_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "APPROVED_FILES = \"approved_files\"\n",
        "\n",
        "def approve_suggested_files(tool_context:ToolContext) -> Dict[str, Any]:\n",
        "    f\"\"\"Approves the {SUGGESTED_FILES} in state for further processing as {APPROVED_FILES}.\"\"\"\n",
        "    \n",
        "    if SUGGESTED_FILES not in tool_context.state:\n",
        "        return tool_error(\"Current files have not been set. Take no action other than to inform user.\")\n",
        "\n",
        "    tool_context.state[APPROVED_FILES] = tool_context.state[SUGGESTED_FILES]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List of tools for the file suggestion agent\n",
        "file_suggestion_agent_tools = [get_approved_user_goal, list_import_files, sample_file, set_suggested_files, approve_suggested_files]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Construct the Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Finally, construct the agent\n",
        "\n",
        "file_suggestion_agent = Agent(\n",
        "    name=\"file_suggestion_agent_v1\",\n",
        "    model=llm, # defined earlier in a variable\n",
        "    description=\"Helps the user select files to import.\",\n",
        "    instruction=file_suggestion_agent_instruction,\n",
        "    tools=file_suggestion_agent_tools,\n",
        ")\n",
        "\n",
        "print(f\"Agent '{file_suggestion_agent.name}' created.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zKGVwRkSduA"
      },
      "source": [
        "---\n",
        "\n",
        "## Interact with the Agent\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZJr8lbkSebH"
      },
      "outputs": [],
      "source": [
        "# Define an Agent Caller Utility\n",
        "# This will provide a simple \"call\" interface and access to the session\n",
        "\n",
        "from helpers import make_agent_caller\n",
        "\n",
        "file_suggestion_caller = make_agent_caller(file_suggestion_agent, {\n",
        "    \"approved_user_goal\": {\n",
        "        \"kind_of_graph\": \"movie graph\", # TODO: change to a BOM graph\n",
        "        \"description\": \"Movies, actors and acted-in relationships for study of co-acting group behaviors.\"\n",
        "    }   \n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEd2QhHyUKY8"
      },
      "outputs": [],
      "source": [
        "# Run the Initial Conversation\n",
        "await file_suggestion_caller.call(\"What files can we use for import?\", True)\n",
        "\n",
        "print(\"Suggested files: \", file_suggestion_caller.session.state[SUGGESTED_FILES])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Agree with the file suggestions\n",
        "await file_suggestion_caller.call(\"Yes, let's do it!\", True)\n",
        "\n",
        "print(\"Approved files: \", file_suggestion_caller.session.state[APPROVED_FILES])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbUzAGvsmB2a"
      },
      "source": [
        "---\n",
        "\n",
        "Congratulations\\! You've created a basic human-in-the-loop interaction, with a structured result.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Bonus, An Interactive Conversation\n",
        "\n",
        "Now, let's make this interactive so you can ask your own questions! Run the cell below. It will prompt you to enter your queries directly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "async def run_interactive_conversation():\n",
        "    while True:\n",
        "        user_query = input(\"Ask me something (or type 'exit' to quit): \")\n",
        "        if user_query.lower() == 'exit':\n",
        "            break\n",
        "        response = await file_suggestion_caller.call(user_query, True)\n",
        "        print(f\"Response: {response}\")\n",
        "\n",
        "# Execute the interactive conversation\n",
        "await run_interactive_conversation()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
